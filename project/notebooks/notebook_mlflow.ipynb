{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import joblib\n",
    "\n",
    "# Retornar para a pasta 'src' para poder importar os módulos criados em 'data/', 'utils/', etc\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "\n",
    "# import yaml consig file\n",
    "from utils.utils import load_config_file\n",
    "\n",
    "# Data load step\n",
    "from data.data_load import DataLoad \n",
    "\n",
    "# Data validation step\n",
    "from data.data_validation import DataValidation \n",
    "\n",
    "# Data transformation step\n",
    "from data.data_transformation import DataTransformation \n",
    "\n",
    "# Data preprocessing step\n",
    "from data.data_preprocessing import DataPreprocessing\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# imputers and discretizers\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser, EqualWidthDiscretiser\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sklearn wrapper\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "# import yaml consig file\n",
    "from utils.utils import load_config_file\n",
    "\n",
    "# Train model step\n",
    "from train.train import ModelTraining\n",
    "\n",
    "# Model validation step\n",
    "from evaluation.classifier_evaluation import ModelEvaluating\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading yaml file\n",
    "yaml_file = load_config_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-24 12:43:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStaring data loading with: train_dataset_name\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData loaded successfully!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>TaxaDeUtilizacaoDeLinhasNaoGarantidas</th>\n",
       "      <th>Idade</th>\n",
       "      <th>NumeroDeVezes30-59DiasAtrasoNaoPior</th>\n",
       "      <th>TaxaDeEndividamento</th>\n",
       "      <th>RendaMensal</th>\n",
       "      <th>NumeroDeLinhasDeCreditoEEmprestimosAbertos</th>\n",
       "      <th>NumeroDeVezes90DiasAtraso</th>\n",
       "      <th>NumeroDeEmprestimosOuLinhasImobiliarias</th>\n",
       "      <th>NumeroDeVezes60-89DiasAtrasoNaoPior</th>\n",
       "      <th>NumeroDeDependentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65818</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.23381</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03605</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  TaxaDeUtilizacaoDeLinhasNaoGarantidas  Idade  \\\n",
       "0       1                               0.766127     45   \n",
       "1       0                               0.957151     40   \n",
       "2       0                                0.65818     38   \n",
       "3       0                                0.23381     30   \n",
       "4       0                               0.907239     49   \n",
       "\n",
       "   NumeroDeVezes30-59DiasAtrasoNaoPior  TaxaDeEndividamento  RendaMensal  \\\n",
       "0                                    2             0.802982       9120.0   \n",
       "1                                    0             0.121876       2600.0   \n",
       "2                                    1             0.085113       3042.0   \n",
       "3                                    0              0.03605       3300.0   \n",
       "4                                    1             0.024926      63588.0   \n",
       "\n",
       "   NumeroDeLinhasDeCreditoEEmprestimosAbertos  NumeroDeVezes90DiasAtraso  \\\n",
       "0                                          13                          0   \n",
       "1                                           4                          0   \n",
       "2                                           2                          1   \n",
       "3                                           5                          0   \n",
       "4                                           7                          0   \n",
       "\n",
       "   NumeroDeEmprestimosOuLinhasImobiliarias  \\\n",
       "0                                        6   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        1   \n",
       "\n",
       "   NumeroDeVezes60-89DiasAtrasoNaoPior  NumeroDeDependentes  \n",
       "0                                    0                    2  \n",
       "1                                    0                    1  \n",
       "2                                    0                    0  \n",
       "3                                    0                    0  \n",
       "4                                    0                    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating 'data_loader' object\n",
    "\n",
    "data_loader = DataLoad()\n",
    "\n",
    "# loading csv file as dataframe from yaml config file using 'load_data()' method \n",
    "\n",
    "df = data_loader.load_data('train_dataset_name')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting data shape checking\u001b[0m\n",
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData shape validation started!\u001b[0m\n",
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mStarting column types validation\u001b[0m\n",
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mColumn validation passed!\u001b[0m\n",
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation step concluded!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating 'data_validator' object\n",
    "\n",
    "data_validator = DataValidation()\n",
    "\n",
    "\n",
    "# run data validation\n",
    "data_validator.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data transformation (split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTarget 'target' variable found in the dataframe. Performing X, y split and train/val split\u001b[0m\n",
      "\u001b[2m2024-03-24 12:43:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData split performed successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instantiating 'data_transformer' object\n",
    "\n",
    "data_transformer = DataTransformation(df)\n",
    "\n",
    "\n",
    "# getting X_train, X_val, y_train, y_val splits\n",
    "X_train, X_val, y_train, y_val = data_transformer.train_test_data_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Experimentations (MLFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1711251631903, experiment_id='1', last_update_time=1711251631903, lifecycle_stage='active', name='prob_loan_exp', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir o servidor do MLFlow:\n",
    "# fazer a ligação entre os códigos executados nesse notebook com a UI do MLFlow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "#mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "# Criar um novo experimento:\n",
    "mlflow.set_experiment('prob_loan_exp') # definir o nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipeline started...\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipeline fitting started...\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPipeline fitting finished!\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData transformation with fitted pipeline started...\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData transformation with fitted pipeline finished!\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData transformation with fitted pipeline started...\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData transformation with fitted pipeline finished!\u001b[0m\n",
      "/home/guhduarte/Repos/MLFlow_Loan/project/models/Logistic_Regression.joblib\n",
      "\u001b[2m2024-03-24 11:53:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation started...\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFitted model: LogisticRegression()\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mScoring metric: roc_auc\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation finished successfully!\u001b[0m\n",
      "\u001b[2m2024-03-24 11:53:12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel validation started...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Criar um experimento base (execução/run)\n",
    "\n",
    "with mlflow.start_run(run_name='baseline_test'):\n",
    "\n",
    "    mlflow.set_tag('model_name', 'lr_baseline')\n",
    "\n",
    "\n",
    "    # 1.0 Preprocessar os dados: =============================================\n",
    "\n",
    "    pipeline =  Pipeline(\n",
    "                    [\n",
    "                     ('imputer', MeanMedianImputer(variables=yaml_file['variables_imputer'])),\n",
    "                                         \n",
    "                     ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "                                                                              ]\n",
    "                      )\n",
    "    \n",
    "    # Instantiating 'data_preprocessor' object from DataPreprocessing class\n",
    "    data_preprocessor = DataPreprocessing(pipeline)\n",
    "\n",
    "    # Fitting pipeline\n",
    "    data_preprocessor.fit_pipeline(X_train)\n",
    "\n",
    "\n",
    "    # Transforming data\n",
    "    \n",
    "    X_train_processed = data_preprocessor.transform_pipeline(X_train) # X_train\n",
    "    \n",
    "    X_val_processed = data_preprocessor.transform_pipeline(X_val) # X_val\n",
    "\n",
    "    joblib.dump(data_preprocessor, '../models/preprocessor.joblib')\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # 1.1 logar um artefato (proprocessor)\n",
    "    mlflow.log_artifact('../models/preprocessor.joblib')\n",
    "\n",
    "    # 1.2 logar os parâmetros do proprocessador\n",
    "    mlflow.log_params(params={'imputer':pipeline['imputer'],\n",
    "                              'scaler':pipeline['scaler']})\n",
    "    \n",
    "\n",
    "\n",
    "    # 2.0 Treinamento do modelo e Cross validation: =============================================\n",
    "\n",
    "    model_instance = LogisticRegression()\n",
    "\n",
    "    # Instantiating 'model_trainer' object from DataPreprocessing class\n",
    "    model_trainer = ModelTraining(X_train_processed, y_train)\n",
    "\n",
    "    # Fitting model\n",
    "    fitted_model = model_trainer.fit(model_instance)\n",
    "\n",
    "    # Instantiating 'model_evaluator' object from DataPreprocessing class\n",
    "    model_evaluator = ModelEvaluating(fitted_model, X_train_processed, y_train)\n",
    "\n",
    "\n",
    "    # Getting metric scores\n",
    "    scores = model_evaluator.cross_val_evaluation()\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # 2.1 logar o resultado da métrica do modelo\n",
    "    mlflow.log_metric('CV_roc_auc', scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "    # 3.0 Treinamento do modelo =============================================\n",
    "    \n",
    "    # Fitting model\n",
    "    model_instance.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "    # 4.0 Salvar metricas do X_val\n",
    "    y_val_probas = model_instance.predict_proba(X_val_processed)[:,1]\n",
    "    X_val_roc_auc = model_evaluator.evaluate_predictions(y_val, y_val_probas)\n",
    "\n",
    "    # logar o resultado da métrica do modelo\n",
    "    mlflow.log_metric('Val_roc_auc', X_val_roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "    # 5.0 Logar o modelo\n",
    "    mlflow.sklearn.log_model(model_instance, 'lr_model', pyfunc_predict_fn='predict_proba')\n",
    "\n",
    "\n",
    "    # end run\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No experimento anterior (run = 'baseline') foi realizado o fit do modelo sem o discretizer no pipeline\n",
    "# No experimento abaixo será incluído o discretizer ao pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar módulo que salva o experimento apenas de atingir um threshold predefinido\n",
    "from mlflow.models import MetricThreshold, infer_signature\n",
    "\n",
    "# Importar classificador dummy para comparação\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um experimento base (execução/run)\n",
    "\n",
    "with mlflow.start_run(run_name='with_discretizer'):\n",
    "\n",
    "    mlflow.set_tag('model_name', 'lr_discretizer')\n",
    "\n",
    "\n",
    "    # 1.0 Preprocessar os dados: =============================================\n",
    "\n",
    "    pipeline =  Pipeline(\n",
    "                    [\n",
    "                     ('imputer', MeanMedianImputer(variables=yaml_file['variables_imputer'])),\n",
    "\n",
    "\n",
    "                     ('discretizer', EqualFrequencyDiscretiser(variables=yaml_file['variables_discretiser'])),                  \n",
    "                     \n",
    "                                        \n",
    "                     ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "                                                                              ]\n",
    "                      )\n",
    "    \n",
    "    # Instantiating 'data_preprocessor' object from DataPreprocessing class\n",
    "    data_preprocessor = DataPreprocessing(pipeline)\n",
    "\n",
    "    # Fitting pipeline\n",
    "    data_preprocessor.fit_pipeline(X_train)\n",
    "\n",
    "\n",
    "    # Transforming data\n",
    "    \n",
    "    X_train_processed = data_preprocessor.transform_pipeline(X_train) # X_train\n",
    "    \n",
    "    X_val_processed = data_preprocessor.transform_pipeline(X_val) # X_val\n",
    "\n",
    "    joblib.dump(data_preprocessor, '../models/preprocessor.joblib')\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # 1.1 logar um artefato (proprocessor)\n",
    "    mlflow.log_artifact('../models/preprocessor.joblib')\n",
    "\n",
    "    # 1.2 logar os parâmetros do proprocessador\n",
    "    mlflow.log_params(params={'imputer':pipeline['imputer'],\n",
    "                              'discretizer':pipeline['discretizer'],\n",
    "                              'scaler':pipeline['scaler']})\n",
    "    \n",
    "\n",
    "\n",
    "    # 2.0 Treinamento do modelo e Cross validation: =============================================\n",
    "\n",
    "    model_instance = LogisticRegression()\n",
    "\n",
    "    # Instantiating 'model_trainer' object from DataPreprocessing class\n",
    "    model_trainer = ModelTraining(X_train_processed, y_train)\n",
    "\n",
    "    # Fitting model\n",
    "    fitted_model = model_trainer.fit(model_instance)\n",
    "\n",
    "    # Instantiating 'model_evaluator' object from DataPreprocessing class\n",
    "    model_evaluator = ModelEvaluating(fitted_model, X_train_processed, y_train)\n",
    "\n",
    "\n",
    "    # Getting metric scores\n",
    "    scores = model_evaluator.cross_val_evaluation()\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # 2.1 logar o resultado da métrica do modelo\n",
    "    mlflow.log_metric('CV_roc_auc', scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "    # 3.0 Treinamento do modelo =============================================\n",
    "    \n",
    "    # Fitting model\n",
    "    model_instance.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "    # 4.0 Salvar metricas do X_val\n",
    "    y_val_probas = model_instance.predict_proba(X_val_processed)[:,1]\n",
    "    X_val_roc_auc = model_evaluator.evaluate_predictions(y_val, y_val_probas)\n",
    "\n",
    "    # logar o resultado da métrica do modelo\n",
    "    mlflow.log_metric('Val_roc_auc', X_val_roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "    # 5.0 Logar o modelo candidato e capturar a uri para mlflow.evaluate\n",
    "    model_candidate_uri = mlflow.sklearn.log_model(model_instance,\n",
    "                                               'lr_model').model_uri\n",
    "\n",
    "\n",
    "    # ===============================\n",
    "\n",
    "    # Inferir assinatura dos dados (aparece o dataset no MLFlow)\n",
    "    signature = infer_signature(X_val_processed, y_val)\n",
    "\n",
    "    # Separar os dados para avaliação do MLFlow (p/ usar no método mlflow.evaluate()):\n",
    "    eval_data = X_val_processed.copy() # criando uma cópia de X_val_processed\n",
    "    eval_data['label'] = y_val # criando a coluna target\n",
    "\n",
    "\n",
    "    # Definindo o threshold do experimento\n",
    "    thresholds = {\n",
    "        yaml_file.get('metric_to_evaluate'): MetricThreshold(\n",
    "            \n",
    "            threshold=yaml_file.get('metric_threshold'), # a métrica precisa ser maior que esse valor para que o experimento seja salvo\n",
    "            \n",
    "            min_absolute_change=yaml_file.get('metric_min_absolute_change'),\n",
    "            \n",
    "            min_relative_change=yaml_file.get('metric_min_relative_change'),\n",
    "            \n",
    "            greater_is_better=yaml_file.get('greater_is_better')\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Instanciando o classificador dummy\n",
    "    baseline_model_instance = DummyClassifier(strategy='uniform').fit(X_train_processed, y_train)\n",
    "\n",
    "    \n",
    "    # Logar o modelo dummy e capturar a uri para mlflow.evaluate\n",
    "    baseline_model_instance_uri = mlflow.sklearn.log_model(baseline_model_instance,\n",
    "                                                           'baseline_model',\n",
    "                                                           signature=signature).model_uri\n",
    "    \n",
    "\n",
    "\n",
    "    # Iniciar avaliação:\n",
    "\n",
    "    # processo responsável por avaliar/comparar modelos no MLFlow\n",
    "    mlflow.evaluate(model_candidate_uri,\n",
    "                    eval_data,\n",
    "                    targets='label',\n",
    "                    model_type=yaml_file.get('model_type'),\n",
    "                    validation_thresholds=thresholds,\n",
    "                    baseline_model=baseline_model_instance_uri)\n",
    "    \n",
    "\n",
    "    # Explicabilidade com SHAP\n",
    "    mlflow.shap.log_explanation(model_instance.predict, X_val_processed)\n",
    "\n",
    "\n",
    "    # end run\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rascunhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artifact_location': 'mlflow-artifacts:/1',\n",
       " 'creation_time': 1711210130178,\n",
       " 'experiment_id': '1',\n",
       " 'last_update_time': 1711212335290,\n",
       " 'lifecycle_stage': 'deleted',\n",
       " 'name': 'prob_loan',\n",
       " 'tags': {}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo o id do experimento\n",
    "\n",
    "experiment_name = \"prob_loan\"\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment_name))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "current_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artifact_location': 'mlflow-artifacts:/2',\n",
       " 'creation_time': 1711212708474,\n",
       " 'experiment_id': '2',\n",
       " 'last_update_time': 1711212708474,\n",
       " 'lifecycle_stage': 'active',\n",
       " 'name': 'prob_loan_exp',\n",
       " 'tags': {}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo o id do experimento\n",
    "\n",
    "experiment_name = \"prob_loan_exp\"\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment_name))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "current_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: No Experiment with id=1 exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/MLFlow_Loan/lib/python3.12/site-packages/mlflow/tracking/fluent.py:1684\u001b[0m, in \u001b[0;36mdelete_experiment\u001b[0;34m(experiment_id)\u001b[0m\n",
      "\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_experiment\u001b[39m(experiment_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   1653\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   1654\u001b[0m \u001b[38;5;124;03m    Delete an experiment from the backend store.\u001b[39;00m\n",
      "\u001b[1;32m   1655\u001b[0m \n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1682\u001b[0m \n",
      "\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m-> 1684\u001b[0m     \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/MLFlow_Loan/lib/python3.12/site-packages/mlflow/tracking/client.py:628\u001b[0m, in \u001b[0;36mMlflowClient.delete_experiment\u001b[0;34m(self, experiment_id)\u001b[0m\n",
      "\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m, experiment_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    596\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Delete an experiment from the backend store.\u001b[39;00m\n",
      "\u001b[1;32m    597\u001b[0m \n",
      "\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    This deletion is a soft-delete, not a permanent deletion. Experiment names can not be\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    626\u001b[0m \n",
      "\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/MLFlow_Loan/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:267\u001b[0m, in \u001b[0;36mTrackingServiceClient.delete_experiment\u001b[0;34m(self, experiment_id)\u001b[0m\n",
      "\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m, experiment_id):\n",
      "\u001b[1;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Delete an experiment from the backend store.\u001b[39;00m\n",
      "\u001b[1;32m    262\u001b[0m \n",
      "\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n",
      "\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m        experiment_id: The experiment ID returned from ``create_experiment``.\u001b[39;00m\n",
      "\u001b[1;32m    265\u001b[0m \n",
      "\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/MLFlow_Loan/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:121\u001b[0m, in \u001b[0;36mRestStore.delete_experiment\u001b[0;34m(self, experiment_id)\u001b[0m\n",
      "\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m, experiment_id):\n",
      "\u001b[1;32m    120\u001b[0m     req_body \u001b[38;5;241m=\u001b[39m message_to_json(DeleteExperiment(experiment_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(experiment_id)))\n",
      "\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDeleteExperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/MLFlow_Loan/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:60\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n",
      "\u001b[1;32m     58\u001b[0m endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n",
      "\u001b[1;32m     59\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n",
      "\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/MLFlow_Loan/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:220\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n",
      "\u001b[1;32m    218\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n",
      "\u001b[1;32m    219\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n",
      "\u001b[0;32m--> 220\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    221\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;32m    222\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "\n",
      "File \u001b[0;32m~/.conda/envs/MLFlow_Loan/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:152\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n",
      "\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n",
      "\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n",
      "\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    154\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m    155\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    156\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    157\u001b[0m         )\n",
      "\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_DOES_NOT_EXIST: No Experiment with id=1 exists"
     ]
    }
   ],
   "source": [
    "# Deletar experimento\n",
    "\n",
    "import mlflow\n",
    "mlflow.delete_experiment(experiment_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/2', creation_time=1711212708474, experiment_id='2', last_update_time=1711212708474, lifecycle_stage='active', name='prob_loan_exp', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1711209927294, experiment_id='0', last_update_time=1711209927294, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "all_experiments = client.search_experiments()\n",
    "\n",
    "all_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/cab6bf40fbd04598b853dcdfc3a70580/lr_model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: lr_model\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: cab6bf40fbd04598b853dcdfc3a70580"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           12Gi       1.7Gi       9.7Gi       0.0Ki       993Mi        10Gi\n",
      "Swap:         4.0Gi          0B       4.0Gi\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLFlow_Loan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
